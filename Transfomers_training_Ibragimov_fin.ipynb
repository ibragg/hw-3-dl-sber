{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание Transformers Training (50 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом домашнем задании требуется обучить несколько Transformer-based моделей в задаче машинного перевода. Для обучения можно воспользоваться текущим проектом, так и реализовать свой пайплайн обучения. Если будете использовать проект, теги **TODO** проекта отмечают, какие компоненты надо реализовать.\n",
    "В ноутбуке нужно только отобразить результаты обучения и выводы. Архитектура модели(количетсво слоев, размерность и тд) остается на ваш выбор.\n",
    "\n",
    "Ваш код обучения нужно выложить на ваш github, в строке ниже дать ссылку на него. В первую очередь будут оцениваться результаты в ноутбуке, код нужен для проверки адекватности результатов. \n",
    "\n",
    "Обучать модели до конца не нужно, только для демонстрации, что модель обучается и рабочая - снижение val_loss, рост bleu_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сcылка на ваш github с проектом(вставить свой) - https://github.com/ibragg/hw-3-dl-sber/tree/main\n",
    "\n",
    "Ноутбук с результатами выкладывать на ваш **google диск** курса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение Seq2seq Transformer модель(25 баллов)\n",
    "\n",
    "Реализуйте Seq2seq Transformer. В качестве блока трансформера можно использовать https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html. В качестве токенизатора воспользуйтесь HuggingFace токенизатор для source/target языков - https://huggingface.co/docs/transformers/fast_tokenizers\n",
    "В качестве максимальной длинны возьмите предложения длинной **до 15 слов**, без каких либо префиксов. \n",
    "\n",
    "Не забудьте остальные элементы модели:\n",
    "* Мы можем использовать 1 трансформер как энкодер - декодером будет выступать линейный слой. \n",
    "* Обучите свой BPE токенизатор - https://huggingface.co/docs/transformers/fast_tokenizers\n",
    "* Матрицу эмбеддингов токенов\n",
    "* Матрицу позицонных эмбеддингов\n",
    "* Линейный слой проекции в target словарь\n",
    "* Функцию маскирования будущих состояний attention, так как модель авто-регрессионна\n",
    "* Learning rate schedualer\n",
    "\n",
    "\n",
    "В качестве результатов, приложите слудующие данные:\n",
    "1) Параметры обучения - learning rate, batch_size, epoch_num, размерность скрытого слоя, количетсво слоев\n",
    "2) Графики обучения - train loss, val loss, bleu score\n",
    "3) Примеры переводов вашей модели(10 штук) - source text, true target text, predicted target text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1634055814777,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "Ic_m7aTfQq5o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import csv\n",
    "import shutil\n",
    "import random\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1634055814778,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "nzlz2fX6Qq5o"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WARcO3ARQq5o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1634055814778,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "5JlFwxbuQq5p",
    "outputId": "e4907c1c-e385-4c10-9f50-d89fb297c90e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pairs: 50000\n",
      "Sample pair:\n",
      "['It offers self-catering cottages, a shared terrace with outdoor furniture and BBQ facilities.', 'К вашим услугам общая меблированная терраса, принадлежности для барбекю и коттеджи с собственной кухней.']\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/data.txt\") as f:\n",
    "    pairs = list(csv.reader(f, delimiter=\"\\t\", quotechar='\"'))\n",
    "    \n",
    "print(f\"Total number of pairs: {len(pairs)}\")\n",
    "print(f\"Sample pair:\\n{random.choice(pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1634055814779,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "yyquWr1tQq5p",
    "outputId": "2fde2ccb-652b-476d-cb62-357cad4d1b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.8075\n",
      "val: 0.1425\n",
      "test: 0.05\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(pairs, test_size=0.05, random_state=1)\n",
    "train, val = train_test_split(train, test_size=0.15, random_state=1)\n",
    "\n",
    "print(f\"train: {len(train) / len(pairs)}\")\n",
    "print(f\"val: {len(val) / len(pairs)}\")\n",
    "print(f\"test: {len(test) / len(pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634055814779,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "RsNXcML9Qq5q"
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.tokenizer = WordPunctTokenizer()\n",
    "\n",
    "    def __call__(self, text, split=True):\n",
    "        \"\"\"\n",
    "            text: text\n",
    "            split: if split to tokens\n",
    "            \n",
    "            returns: indexes list\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "        if split:\n",
    "            text = self.tokenizer.tokenize(text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def get_unique_vocab(self, corpus, min_freq=3):\n",
    "        \"\"\"\n",
    "            get unique words from a list of sentences\n",
    "        \"\"\"\n",
    "        corpus_words = list(map(self, corpus))\n",
    "        words = Counter(list(itertools.chain(*corpus_words)))\n",
    "        words = [word[0] for word in words.items() if word[1] >= 3]\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634055814780,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "C5fp7fyWQq5q"
   },
   "outputs": [],
   "source": [
    "class TextTokenizer:\n",
    "    \n",
    "    def __init__(self, vocab, text_preprocessor):\n",
    "        \"\"\"\n",
    "            vocab: words from training set\n",
    "        \"\"\"\n",
    "        self.pad_token = \"<pad>\"\n",
    "        self.sos_token = \"<sos>\"\n",
    "        self.eos_token = \"<eos>\"\n",
    "        self.unk_token = \"<unk>\"\n",
    "        self.additional_tokens = [self.pad_token, self.sos_token, self.eos_token, self.unk_token]\n",
    "        \n",
    "        self.text_preprocessor = text_preprocessor\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.word2index = dict(zip(\n",
    "            self.additional_tokens + vocab,\n",
    "            range(len(vocab) + len(self.additional_tokens))\n",
    "        ))\n",
    "        \n",
    "        self.index2word = {v: k for k, v in self.word2index.items()}\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        \"\"\"\n",
    "            returns: number of words in dict\n",
    "        \"\"\"\n",
    "        return len(self.word2index)\n",
    "    \n",
    "    def detokenize(self, indexes, remove_tech_tokens=True):\n",
    "        if remove_tech_tokens:\n",
    "            return \" \".join([self.index2word[idx] for idx in indexes if self.index2word[idx] not in self.additional_tokens])\n",
    "        else:\n",
    "            return \" \".join([self.index2word[idx] for idx in indexes])\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        \"\"\"\n",
    "            text: text\n",
    "            \n",
    "            returns: indexes list\n",
    "        \"\"\"\n",
    "        text = self.text_preprocessor(text)\n",
    "        indexes = [self.word2index[self.sos_token]] +\\\n",
    "                  [self.word2index[token] if token in self.word2index else self.word2index[self.unk_token] \\\n",
    "                   for token in text] +\\\n",
    "                  [self.word2index[self.eos_token]]\n",
    "        \n",
    "        return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1149,
     "status": "ok",
     "timestamp": 1634055815921,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "awtTiXqKQq5r",
    "outputId": "a0de9c14-7a26-4e0d-8eed-2c22fbb5a159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens in ru vocab: 9367\n",
      "number of tokens in en vocab: 6738\n"
     ]
    }
   ],
   "source": [
    "text_preprocessor = TextPreprocessor()\n",
    "\n",
    "ru_vocab = text_preprocessor.get_unique_vocab([pair[1] for pair in train])\n",
    "en_vocab = text_preprocessor.get_unique_vocab([pair[0] for pair in train])\n",
    "\n",
    "ru_tokenizer = TextTokenizer(ru_vocab, text_preprocessor)\n",
    "en_tokenizer = TextTokenizer(en_vocab, text_preprocessor)\n",
    "print(f\"number of tokens in ru vocab: {ru_tokenizer.vocab_size}\")\n",
    "print(f\"number of tokens in en vocab: {en_tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634055815921,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "9FtF3k4XQq5r"
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, src, trg, src_tokenizer, trg_tokenizer):\n",
    "        \"\"\"\n",
    "            src: source language sentences\n",
    "            trg: target language sentences\n",
    "            src_tokenizer: source language tokenizer\n",
    "            trg_tokenizer: target language tokenizer\n",
    "        \"\"\"\n",
    "        self.src = src\n",
    "        self.trg = trg\n",
    "        \n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer\n",
    "        \n",
    "        self.data = []\n",
    "        for s, t in zip(src, trg):\n",
    "            self.data.append((self.src_tokenizer(s), self.trg_tokenizer(t)))\n",
    "                \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            returns: number of pairs\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "            returns: ([indexes of source sentence], [indexes of target sentence])\n",
    "        \"\"\"\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1708,
     "status": "ok",
     "timestamp": 1634055817627,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "Cj3uIZRWQq5s"
   },
   "outputs": [],
   "source": [
    "train_dataset = TranslationDataset(\n",
    "    src=[pair[1] for pair in train],\n",
    "    trg=[pair[0] for pair in train],\n",
    "    src_tokenizer=ru_tokenizer,\n",
    "    trg_tokenizer=en_tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = TranslationDataset(\n",
    "    src=[pair[1] for pair in val],\n",
    "    trg=[pair[0] for pair in val],\n",
    "    src_tokenizer=ru_tokenizer,\n",
    "    trg_tokenizer=en_tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = TranslationDataset(\n",
    "    src=[pair[1] for pair in test],\n",
    "    trg=[pair[0] for pair in test],\n",
    "    src_tokenizer=ru_tokenizer,\n",
    "    trg_tokenizer=en_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1634055817630,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "RZ4Hx9Q8Qq5s",
    "outputId": "e164257c-f109-4b1a-94a4-8ee95872a2ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The kitchen is equipped with a dishwasher.', 'Кухня оснащена посудомоечной машиной.']\n",
      "([1, 177, 1559, 427, 428, 20, 2], [1, 80, 171, 6, 170, 8, 9, 178, 22, 2])\n",
      "[177, 1559, 427, 428, 20]\n",
      "кухня оснащена посудомоечной машиной .\n",
      "the kitchen is equipped with a dishwasher .\n"
     ]
    }
   ],
   "source": [
    "print(train[-2])\n",
    "print(train_dataset[-2])\n",
    "print([ru_tokenizer.word2index[word] for word in text_preprocessor(train[-2][1])])\n",
    "print(ru_tokenizer.detokenize(train_dataset[-2][0]))\n",
    "print(en_tokenizer.detokenize(train_dataset[-2][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1634055817631,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "2RFq7bDNQq5s"
   },
   "outputs": [],
   "source": [
    "src_pad_idx = ru_tokenizer.word2index[\"<pad>\"]\n",
    "trg_pad_idx = en_tokenizer.word2index[\"<pad>\"]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "        batch: pair of lists of words indexes\n",
    "        \n",
    "        returns: list of src, list of trg\n",
    "    \"\"\"\n",
    "    src, trg = map(list, zip(*batch))\n",
    "    max_src = max(list(map(len, src)))\n",
    "    max_trg = max(list(map(len, trg)))\n",
    "    src = torch.tensor([s + [src_pad_idx] * (max_src - len(s)) for s in src])\n",
    "    trg = torch.tensor([t + [trg_pad_idx] * (max_trg - len(t)) for t in trg])\n",
    "    \n",
    "    return src, trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1634055817631,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "3WnmlrmUQq5s",
    "outputId": "da12d53b-e03c-42eb-b74a-2b13b1771ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 47])\n",
      "torch.Size([32, 39])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   4,   5,  ...,   0,   0,   0],\n",
       "        [  1,  21,  22,  ...,   0,   0,   0],\n",
       "        [  1,  34,   3,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  1, 259,  23,  ...,   0,   0,   0],\n",
       "        [  1,  76,  77,  ...,   0,   0,   0],\n",
       "        [  1, 279, 159,  ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "src, trg = batch\n",
    "print(src.shape)\n",
    "print(trg.shape)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=output_dim,\n",
    "            embedding_dim=emb_dim\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hid_dim,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(\n",
    "            in_features=hid_dim,\n",
    "            out_features=output_dim\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        #input = [batch size, 1]\n",
    "        input = input.unsqueeze(1)\n",
    "        \n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.out(output.squeeze(1))\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1634055817632,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "MqQFbQzsQq5t"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim=emb_dim\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hid_dim,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        embedded = self.embedding(src)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src sent len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return output, (hidden, cell)\n",
    "    \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[0]\n",
    "        max_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, max_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[:, 0]\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            \n",
    "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            outputs[:,t,:] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1] # max on every batch, pick indexes\n",
    "            input = (trg[:, t] if teacher_force else top1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=output_dim,\n",
    "            embedding_dim=emb_dim\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hid_dim,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.W_attn = nn.Linear(hid_dim, hid_dim, bias=False)\n",
    "        \n",
    "        self.out = nn.Linear(\n",
    "            in_features=2*hid_dim,\n",
    "            out_features=output_dim\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        \n",
    "        input = input.unsqueeze(1)\n",
    "        \n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        _, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        ht_x_W = self.W_attn(hidden[-1]).unsqueeze(-1) # take hidden state only from last layer [B, HID_DIM, 1]\n",
    "        scores = F.softmax(torch.bmm(encoder_outputs, ht_x_W), dim=1) # encoder_outputs = [B, SEQ_LEN, HID_DIM]\n",
    "        weighted_states = encoder_outputs * scores # dim same as encoder_outputs\n",
    "        attention_output = weighted_states.sum(1) # [B, HID_DIM]\n",
    "\n",
    "        prediction = self.out(torch.cat((hidden[-1].squeeze(0), attention_output), dim=-1))\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1634055818021,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "tnjbT4n5Qq5u",
    "outputId": "9b7a0406-ad96-48b3-99a1-63ffccb8b7a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 46, 6738])\n",
      "The model has 18,647,890 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = ru_tokenizer.vocab_size\n",
    "OUTPUT_DIM = en_tokenizer.vocab_size\n",
    "MAX_SEQ_LEN = 100\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device)\n",
    "outputs = model(src, trg)\n",
    "print(outputs.shape)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "src, trg = next(iter(train_dataloader))\n",
    "output, (hidden, cell) = enc(src)\n",
    "input = trg[:, 0]\n",
    "embedded = embedding(input) # input is a batch of single tokens, so embedded = [B, DEC_EMB_DIM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, trg = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1634055818021,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "SCFhPk2nQq5u"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            model, \n",
    "            optimizer, \n",
    "            criterion, \n",
    "            logdir=\"./logs\", \n",
    "            device=None\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion.to(self.device)\n",
    "        self.logdir = logdir\n",
    "        self._writer = SummaryWriter(log_dir=logdir)\n",
    "    \n",
    "    def _calculate_loss(self, batch, train=True):\n",
    "        \"\"\"\n",
    "            batch: \n",
    "            \n",
    "            returns: batch loss\n",
    "        \"\"\"\n",
    "        src, trg = batch\n",
    "        \n",
    "        src = src.to(self.device)\n",
    "        trg = trg.to(self.device)\n",
    "        \n",
    "        if train:\n",
    "            output = self.model(src, trg, self.teacher_forcing_ratio)\n",
    "        else:\n",
    "            output = self.model(src, trg, 0)\n",
    "        \n",
    "        output = output[:,1:].reshape(-1, output.shape[-1])\n",
    "        trg = trg[:,1:].reshape(-1)\n",
    "        \n",
    "        loss = self.criterion(output, trg)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def _train_step(self, dataloader):\n",
    "        \"\"\"\n",
    "            returns: лосс на датасете для обучения\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch in tqdm(dataloader):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss = self._calculate_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), self.clip)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        return epoch_loss / len(dataloader)\n",
    "    \n",
    "    def _eval_step(self, dataloader):\n",
    "        \"\"\"\n",
    "            dataloader: даталоадер для валидации\n",
    "            \n",
    "            returns: лосс на валидации\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                loss = self._calculate_loss(batch, train=False)\n",
    "                epoch_loss += loss\n",
    "            \n",
    "        return epoch_loss / len(dataloader)\n",
    "    \n",
    "    def train(self, dataloaders, n_epochs, clip=1, teacher_forcing_ratio=0.5, verbose=True):\n",
    "        \"\"\"\n",
    "            dataloaders: словарь вида {'train': train_dataloader, 'eval': eval_dataloader}\n",
    "            n_epochs: количество эпох обучения\n",
    "            verbose: нужно ли выводить каждую эпоху информацию про лоссы\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "        self.clip=clip\n",
    "        self.teacher_forcing_ratio=teacher_forcing_ratio\n",
    "        \n",
    "        self._n_epoch = 1\n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss = self._train_step(dataloaders['train'])\n",
    "            eval_loss = self._eval_step(dataloaders['eval'])\n",
    "            \n",
    "            self.train_loss.append(train_loss)\n",
    "            self.val_loss.append(eval_loss)\n",
    "            \n",
    "            if self._writer is not None:\n",
    "                self._writer.add_scalar('train/loss', train_loss, global_step=self._n_epoch)\n",
    "                self._writer.add_scalar('eval/loss', eval_loss, global_step=self._n_epoch)\n",
    "                \n",
    "            if verbose:\n",
    "                print(\n",
    "                    'epoch: {:>2}, train loss: {:.4f}, eval loss: {:.4f}, time: {:.4f}' \\\n",
    "                        .format(epoch + 1, train_loss, eval_loss, time.time() - start)\n",
    "                )\n",
    "                    \n",
    "            self._n_epoch += 1\n",
    "            \n",
    "        self.train_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1634055818022,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "atDGrjJUQq5v",
    "outputId": "56ae4f58-afa0-4adc-f2a1-6b5232045a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1634055818417,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "FQ4IbdtnQq5v"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = ru_tokenizer.vocab_size\n",
    "OUTPUT_DIM = en_tokenizer.vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1634055818418,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "b75xUkk9Qq5v"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "LR = 0.001\n",
    "CLIP = 1\n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"eval\": val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 1367,
     "status": "ok",
     "timestamp": 1634055819782,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "yNuiVA6sQq5w"
   },
   "outputs": [],
   "source": [
    "PAD_IDX = en_tokenizer.word2index[en_tokenizer.pad_token]\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1634056539565,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "v95UVyQNQq5w"
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    \n",
    "    def __init__(self, model, src_tokenizer, trg_tokenizer, device):\n",
    "        \"\"\"\n",
    "            model: model\n",
    "            src_tokenizer: source language tokenizer\n",
    "            trg_tokenizer: target language tokenizer\n",
    "        \"\"\"\n",
    "        self.model = model.to(device)\n",
    "        \n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer\n",
    "        self.device = device\n",
    "        \n",
    "    @staticmethod\n",
    "    def _remove_tech_tokens(mystr, tokens_to_remove=['<eos>', '<sos>', '<unk>', '<pad>']):\n",
    "        return [x for x in mystr if x not in tokens_to_remove]\n",
    "    \n",
    "    def translate_text(self, text):\n",
    "        self.model.eval()\n",
    "        \n",
    "        one_text_dataset = TranslationDataset(\n",
    "            src=[text],\n",
    "            trg=[text],\n",
    "            src_tokenizer=ru_tokenizer,\n",
    "            trg_tokenizer=en_tokenizer\n",
    "        )\n",
    "        one_text_dataloader = DataLoader(one_text_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            src, trg = next(iter(one_text_dataloader))\n",
    "\n",
    "            src = src.to(self.device)\n",
    "            trg = trg.to(self.device)\n",
    "\n",
    "            output = self.model(src, src, 0)\n",
    "\n",
    "            output = output.argmax(dim=-1)\n",
    "\n",
    "            original_text = [self.trg_tokenizer.detokenize(x) for x in trg.detach().cpu().numpy()]\n",
    "            generated_text = [self.trg_tokenizer.detokenize(x) for x in output[:,1:].detach().cpu().numpy()]\n",
    "            \n",
    "        return original_text, generated_text\n",
    "\n",
    "    def translate(self, dataloader):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        original_text = []\n",
    "        generated_text = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader):\n",
    "\n",
    "                src, trg = batch\n",
    "\n",
    "                src = src.to(self.device)\n",
    "                trg = trg.to(self.device)\n",
    "\n",
    "                output = self.model(src, src, 0) # trg doesn't matter\n",
    "\n",
    "                output = output.argmax(dim=-1)\n",
    "\n",
    "                original_text.extend([self.trg_tokenizer.detokenize(x) for x in trg.detach().cpu().numpy()])\n",
    "                generated_text.extend([self.trg_tokenizer.detokenize(x) for x in output[:,1:].detach().cpu().numpy()])\n",
    "                \n",
    "        return original_text, generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1634056539565,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "9P6Be9QqQq5x",
    "outputId": "6be513f1-917d-47c0-9e66-7c25c90b858f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "evaluator = Evaluator(trainer.model, ru_tokenizer, en_tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24417,
     "status": "ok",
     "timestamp": 1634056563967,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "cyyqAiUfQq5x",
    "outputId": "1e755929-8b26-447a-aaf1-ed2a2359f290",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "original_text, generated_text = evaluator.translate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1634056563968,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "SF4_D6VmQq5x",
    "outputId": "ca136cb2-f5cf-4f93-b8a8-1420efd6a251"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The modern rooms are air conditioned and have a balcony. They offer a flat-screen TV and a fridge.',\n",
       "  'Современные номера с балконом оснащены кондиционером, телевизором с плоским экраном и холодильником.'],\n",
       " ['Vivanta by Taj is located in Chennai’s commercial district, 200 metres from Spencer’s Plaza Mall.',\n",
       "  'Отель Vivanta by Taj находится в коммерческом районе города Ченнай, в 200 метрах от торгового центра Spencer’s Plaza.'],\n",
       " ['Towels and bed linen are available.',\n",
       "  'Предоставляются полотенца и постельное белье.'],\n",
       " ['This holiday home is 11 km from Santorini (Thira) Airport.',\n",
       "  'Расстояние до аэропорта Санторини составляет 11 км.'],\n",
       " ['The functional rooms here will provide you with cable TV and air conditioning.',\n",
       "  'Номера отеля отличаются практичным оформлением и имеют телевизор с кабельными каналами и кондиционер.']]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1634056563969,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "lgwItO46Qq5y",
    "outputId": "87866ca9-6b79-4cc9-f956-fc97f9f48e09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the modern rooms are air conditioned and have a balcony . they offer a flat - screen tv and a fridge .',\n",
       " 'by is located in chennai ’ s commercial district , 200 metres from ’ s plaza mall .',\n",
       " 'towels and bed linen are available .',\n",
       " 'this holiday home is 11 km from santorini ( ) airport .',\n",
       " 'the functional rooms here will provide you with cable tv and air conditioning .']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1634056563969,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "cx2v8e4YQq5y",
    "outputId": "5ec36948-229c-4e85-9686-abf3bf669f57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the air - conditioned rooms are air conditioned and feature a flat - screen tv and a seating area . .',\n",
       " 'is located in the heart of , just metres from the of , and metres from the .',\n",
       " 'towels and bed linen are offered . apartment . . .',\n",
       " 'the nearest airport is pulkovo airport , 19 km from the property . . .',\n",
       " 'rooms at the are air conditioned and feature a tv and a minibar . .']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634056563970,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "BCiHj88pQq5y"
   },
   "outputs": [],
   "source": [
    "original_text = [text.split(\" \") for text in original_text]\n",
    "generated_text = [text.split(\" \") for text in generated_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1634056564744,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "b9FxcQabQq5y",
    "outputId": "7af38cf5-bccc-4e95-f1ff-e3e292d0a2c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.56573766349486\n"
     ]
    }
   ],
   "source": [
    "bleu = corpus_bleu([[text] for text in original_text], generated_text) * 100\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1634056564745,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "CBI0qZ0KQq5z"
   },
   "outputs": [],
   "source": [
    "model_name = \"seq2seq\"\n",
    "\n",
    "results[model_name][\"bleu\"] = bleu\n",
    "results[model_name][\"n_params\"] = count_parameters(trainer.model)\n",
    "results[model_name][\"train_time\"] = trainer.train_time\n",
    "results[model_name][\"train_loss\"] = trainer.train_loss\n",
    "results[model_name][\"val_loss\"] = trainer.val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1634056564745,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "l7dvBbJNQq5z"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1634056564746,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "cwXuRZI1Qq5z",
    "outputId": "65e06bff-8bba-429f-aca8-30cc0ca3e0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1634056564746,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "Q_uTbGpEQq50"
   },
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = ru_tokenizer.word2index[\"<pad>\"]\n",
    "TRG_PAD_IDX = en_tokenizer.word2index[\"<pad>\"]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "        batch: pair of lists of words indexes\n",
    "        \n",
    "        returns: list of src, list of trg\n",
    "    \"\"\"\n",
    "    src, trg = map(list, zip(*batch))\n",
    "    \n",
    "    src = list(map(torch.tensor, src))\n",
    "    trg = list(map(torch.tensor, trg))\n",
    "    \n",
    "    src = pad_sequence(src, padding_value=SRC_PAD_IDX)\n",
    "    trg = pad_sequence(trg, padding_value=TRG_PAD_IDX)\n",
    "    \n",
    "    return src, trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1634056564747,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "NxRZv3SUQq50"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"eval\": val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1634056564747,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "ZgpLd7A_Qq50",
    "outputId": "551a77ff-b38b-4b80-9d9a-3504de8a41d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56, 256])\n",
      "torch.Size([46, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   1,   1,  ...,   1,   1,   1],\n",
       "        [  4,  21,  34,  ...,  27, 166, 185],\n",
       "        [  5,  22,   3,  ..., 261, 460, 202],\n",
       "        ...,\n",
       "        [  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "src, trg = batch\n",
    "src = src.to(DEVICE)\n",
    "trg = trg.to(DEVICE)\n",
    "print(src.shape)\n",
    "print(trg.shape)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1634056564747,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "x2lj1QoOQq51"
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == SRC_PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == TRG_PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1634056564748,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "NjsGDFemQq55"
   },
   "outputs": [],
   "source": [
    "src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634056564751,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "Or92wyn4Qq57"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1634056565234,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "zuT4taR1Qq57"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = ru_tokenizer.vocab_size\n",
    "TGT_VOCAB_SIZE = en_tokenizer.vocab_size\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3922,
     "status": "ok",
     "timestamp": 1634056569154,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "0f0ZPCZ6Qq57",
    "outputId": "ae7fb7d3-a831-43da-c72f-63bc5127cab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 256, 6738])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = transformer(src, trg, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1634056569155,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "iYLBvCOHQq58",
    "outputId": "99d72867-883a-4168-faab-5961b393f182"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24327250"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1634056569155,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "iqj7R_RGQq58"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            model, \n",
    "            optimizer, \n",
    "            criterion, \n",
    "            logdir=\"./logs\", \n",
    "            device=None\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion.to(self.device)\n",
    "        self.logdir = logdir\n",
    "        self._writer = SummaryWriter(log_dir=logdir)\n",
    "    \n",
    "    def _calculate_loss(self, batch, train=True):\n",
    "        \"\"\"\n",
    "            batch: \n",
    "            \n",
    "            returns: batch loss\n",
    "        \"\"\"\n",
    "        src, trg = batch\n",
    "        \n",
    "        src = src.to(self.device)\n",
    "        trg = trg.to(self.device)\n",
    "        \n",
    "        tgt_input = trg[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        logits = self.model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = trg[1:, :]\n",
    "        loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def _train_step(self, dataloader):\n",
    "        \"\"\"\n",
    "            returns: лосс на датасете для обучения\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch in tqdm(dataloader):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss = self._calculate_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        return epoch_loss / len(dataloader)\n",
    "    \n",
    "    def _eval_step(self, dataloader):\n",
    "        \"\"\"\n",
    "            dataloader: даталоадер для валидации\n",
    "            \n",
    "            returns: лосс на валидации\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                loss = self._calculate_loss(batch, train=False)\n",
    "                epoch_loss += loss\n",
    "            \n",
    "        return epoch_loss / len(dataloader)\n",
    "    \n",
    "    def train(self, dataloaders, n_epochs, verbose=True):\n",
    "        \"\"\"\n",
    "            dataloaders: словарь вида {'train': train_dataloader, 'eval': eval_dataloader}\n",
    "            n_epochs: количество эпох обучения\n",
    "            verbose: нужно ли выводить каждую эпоху информацию про лоссы\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "        self._n_epoch = 1\n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss = self._train_step(dataloaders['train'])\n",
    "            eval_loss = self._eval_step(dataloaders['eval'])\n",
    "            \n",
    "            self.train_loss.append(train_loss)\n",
    "            self.val_loss.append(eval_loss)\n",
    "            \n",
    "            if self._writer is not None:\n",
    "                self._writer.add_scalar('train/loss', train_loss, global_step=self._n_epoch)\n",
    "                self._writer.add_scalar('eval/loss', eval_loss, global_step=self._n_epoch)\n",
    "                \n",
    "            if verbose:\n",
    "                print(\n",
    "                    'epoch: {:>2}, train loss: {:.4f}, eval loss: {:.4f}, time: {:.4f}' \\\n",
    "                        .format(epoch + 1, train_loss, eval_loss, time.time() - start)\n",
    "                )\n",
    "                    \n",
    "            self._n_epoch += 1\n",
    "            \n",
    "        self.train_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1634056569156,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "Vzft8PnVQq59",
    "outputId": "565c52df-0a85-473c-a0f3-f834df2bce12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1634056569156,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "w0Ie_imlQq59"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"eval\": val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1634056569638,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "lDcjbs5wQq59"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = ru_tokenizer.vocab_size\n",
    "TGT_VOCAB_SIZE = en_tokenizer.vocab_size\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1634056569638,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "fA8cMO8ZQq59"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = en_tokenizer.word2index[en_tokenizer.pad_token])\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "trainer = Trainer(transformer, optimizer, criterion, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1634056569640,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "uejEamt7Qq5-"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 713354,
     "status": "ok",
     "timestamp": 1634057282988,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "lN856XH-Qq5-",
    "outputId": "8cced63f-a32c-429a-fbe0-3daf028afa78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1, train loss: 4.0490, eval loss: 2.8773, time: 47.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2, train loss: 2.7067, eval loss: 2.3709, time: 95.2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3, train loss: 2.2997, eval loss: 2.1065, time: 142.8523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4, train loss: 2.0423, eval loss: 1.9451, time: 190.3232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5, train loss: 1.8547, eval loss: 1.8401, time: 237.9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  6, train loss: 1.7062, eval loss: 1.7620, time: 285.4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7, train loss: 1.5822, eval loss: 1.6902, time: 332.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  8, train loss: 1.4753, eval loss: 1.6493, time: 380.5082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  9, train loss: 1.3837, eval loss: 1.6287, time: 428.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train loss: 1.3025, eval loss: 1.5921, time: 475.6333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, train loss: 1.2278, eval loss: 1.5713, time: 523.2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, train loss: 1.1581, eval loss: 1.5690, time: 570.8011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, train loss: 1.0978, eval loss: 1.5671, time: 618.2905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, train loss: 1.0392, eval loss: 1.5649, time: 665.8689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:45<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, train loss: 0.9868, eval loss: 1.5794, time: 713.3695\n"
     ]
    }
   ],
   "source": [
    "trainer.train(dataloaders, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1634057282990,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "AnMOcEKgQq5-"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == en_tokenizer.word2index[en_tokenizer.eos_token]:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    #src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    src = torch.tensor(ru_tokenizer(text)).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, src, src_mask, max_len=num_tokens + 5, start_symbol=en_tokenizer.word2index[en_tokenizer.sos_token]).flatten()\n",
    "    return en_tokenizer.detokenize(list(tgt_tokens.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1634057282991,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "3PGvLQcTQq5_"
   },
   "outputs": [],
   "source": [
    "_, ru = map(list, zip(*test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1634057282991,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "0A1vHrDKQq5_"
   },
   "outputs": [],
   "source": [
    "original_text = []\n",
    "for _, trg in test_dataloader:\n",
    "    original_text += [en_tokenizer.detokenize(tokens) for tokens in trg.T.detach().cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155071,
     "status": "ok",
     "timestamp": 1634057438048,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "PhNqRqgEQq5_",
    "outputId": "ba5b8027-84fb-476f-d867-e2d3cde17d66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [02:34<00:00, 16.13it/s]\n"
     ]
    }
   ],
   "source": [
    "generated_text = []\n",
    "for text in tqdm(ru):\n",
    "    generated_text.append(translate(trainer.model, text))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "id": "18k3UbKCQq5_"
   },
   "source": [
    "text = \"Современные номера с балконом оснащены кондиционером, телевизором с плоским экраном и холодильником.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1634057438049,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "yS9AhJRuQq5_",
    "outputId": "d3a7222f-7047-4096-bc5d-473dd290fdcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The modern rooms are air conditioned and have a balcony. They offer a flat-screen TV and a fridge.',\n",
       "  'Современные номера с балконом оснащены кондиционером, телевизором с плоским экраном и холодильником.'],\n",
       " ['Vivanta by Taj is located in Chennai’s commercial district, 200 metres from Spencer’s Plaza Mall.',\n",
       "  'Отель Vivanta by Taj находится в коммерческом районе города Ченнай, в 200 метрах от торгового центра Spencer’s Plaza.'],\n",
       " ['Towels and bed linen are available.',\n",
       "  'Предоставляются полотенца и постельное белье.'],\n",
       " ['This holiday home is 11 km from Santorini (Thira) Airport.',\n",
       "  'Расстояние до аэропорта Санторини составляет 11 км.'],\n",
       " ['The functional rooms here will provide you with cable TV and air conditioning.',\n",
       "  'Номера отеля отличаются практичным оформлением и имеют телевизор с кабельными каналами и кондиционер.']]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1634057438050,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "wQoxtIWdQq6A",
    "outputId": "4519f4a6-8595-4c04-cb62-e7803976234c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the modern rooms are air conditioned and have a balcony . they offer a flat - screen tv and a fridge .',\n",
       " 'by is located in chennai ’ s commercial district , 200 metres from ’ s plaza mall .',\n",
       " 'towels and bed linen are available .',\n",
       " 'this holiday home is 11 km from santorini ( ) airport .',\n",
       " 'the functional rooms here will provide you with cable tv and air conditioning .']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1634057438051,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "KCaGVBs7Qq6A",
    "outputId": "ab52f832-b50a-4a30-e93a-86367907da14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modern air - conditioned rooms feature a flat - screen tv and a refrigerator .',\n",
       " 'by is located in the commercial centre of , 200 metres from ’ s plaza .',\n",
       " 'towels and bed linen are offered in this apartment .',\n",
       " 'santorini airport is 11 km away .',\n",
       " 'rooms at the hotel are individually decorated and feature a tv with cable channels .']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1634057438051,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "BkkUFDNhQq6A"
   },
   "outputs": [],
   "source": [
    "original_text = [text.split(\" \") for text in original_text]\n",
    "generated_text = [text.split(\" \") for text in generated_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1634057438535,
     "user": {
      "displayName": "Александр Смирнов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3LUBiuWlo_woqtPR_qeqRj7kvglPwk1cGmPTkiw=s64",
      "userId": "12438224675564049956"
     },
     "user_tz": -180
    },
    "id": "iHHNGh10Qq6A",
    "outputId": "89a4cc94-917a-4c28-ac3f-dd254a890f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.42618242434841\n"
     ]
    }
   ],
   "source": [
    "bleu = corpus_bleu([[text] for text in original_text], generated_text) * 100\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### so, final score is 33"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "02_nlp_nmt.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.324px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
